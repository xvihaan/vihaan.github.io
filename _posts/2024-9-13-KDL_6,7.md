---
layout: single
title:  "5.케창딥 - 머신러닝 프로세스"
categories: [AI, ML, DL]
tags: [keras, deeplearning, KDL]
toc: true
author_profile: false
---


# 머신러닝 프로세스, 배포 기법, 모델 경량화

### 일반화와 모델 평가
---
머신러닝 모델의 성능 평가에서 중요한 역할, 일반화를 높이기 위해 사용할 수 있는 두 가지 방법

- 일반화**란 모델이 훈련 데이터뿐만 아니라 새로운 데이터(테스트 데이터)에서도 잘 작동하는 능력을 의미. 이는 모델이 훈련된 데이터셋의 특성에 과도하게 맞추지 않고, 보편적인 패턴을 학습하는 것을 목표
- 일반화 성능을 높이는 방법**으로는
	- (1) **규제(Regularization)** 기법을 사용하여 모델의 복잡도를 줄이고,
	- (2) **드롭아웃(Dropout)** 등을 통해 모델의 과적합을 방지하는 방법

####  일반화 성능을 극대화 하는 방법 (데이터 2가지 , 모델 2가지 )
 - 데이터 - 2가지
	 - 데이터셋 큐레이션: 양질의 데이터인지 확인(레이블에러, 누락, 특성 선택)
		 - 특성 공학: - 데이터를 더 쉽게 표현 가능한지 확인
		 - ex) 시계이미지 → 각 바늘의 좌표 → 시계 바늘의 각도 등
- 모델 - 2가지
	- 조기종료: (학습 정도를 변경 epochs)
		- 최적의 에포크 수 찾기 - 검증 loss가 향상되지않으면 학습 종료 기법
		- 모델 규제(모델 구조 변경): 모델을 더 간단하게 만드는 방법
            - 모델 규모 감축: 레이어를 없애거나 유닛을 낮춘다
            - 가중치 규제 추가: L1, L2 (각 레이어에 추가된다)
            - 드롭아웃: 무작위 출력 특성을 일부 제외 시키며 학습

### 모델의 하이퍼파라미터 튜닝
---
모델의 하이퍼파라미터를 튜닝하기 위해 K-fold 교차 검증을 사용하는 이유, 데이터셋이 작을 때 K-fold 교차 검증의 장단점을 두 가지로 설명

- **K-fold 교차 검증**은 데이터를 여러 번 나누어 각각 다른 검증셋으로 모델을 평가함으로써, 특정 데이터 분할에 의한 편향을 줄이고 모델의 일반화 성능을 평가하는 데 유용
- **데이터셋이 작을 때** K-fold 교차 검증의 이점
	- (1) **모델이 다양한 데이터 분할에 대해 평가**되어, 작은 데이터셋에서도 모델 성능의 신뢰도를 높일 수 있으며, 
	- (2) **훈련에 사용되는 데이터가 더 많이 사용**될 수 있어, 모델이 더 많은 데이터를 학습

```jsx
# 하이퍼 파라미터 튜닝을 너무 많이 하면 검증 데이터셋에서 과대적합이 일어날수있으니 주의하자
```

### 머신 러닝 워크플로
---
머신 러닝 워크플로에서 모델 개발 단계의 주요 활동, 일반화 성능을 높이기 위한 방법

- **모델 개발 단계**는 데이터를 전처리하고, 모델을 설계하며, 모델의 하이퍼파라미터를 튜닝하는 과정을 포함
- **일반화 성능을 높이기 위한 방법**
- (1) **데이터 증강(data augmentation)** 을 통해 모델이 다양한 상황에 대해 학습
- (2) **교차 검증(cross-validation)** 을 사용해 다양한 데이터 분할에 대해 평가하고 최적의 모델을 선택하는 방법

### 모델 배포
---
모델 배포 단계에서 고려해야 할 중요한 요소, 실전 환경에 배포할 때 발생 도전과제

- **모델 배포 단계**에서는 모델의 성능, 예측 시간, 리소스 사용량, 그리고 실시간 환경에서의 신뢰성 등을 고려
- **도전 과제**로는 실시간 데이터의 변동성, 배포된 모델의 업데이트 및 관리, 실시간 추론 속도와 효율성 등 수행

### 잠재공간
---
#### **매니폴드 vs 보간**
```
- 매니폴드 가설 : 고차원 데이터가 저차원 매니폴드에 놓여있다고 가정 
	- 입력 공간 안에서 간단하고 저차원이고 구조적인부분 공간(잠재 매니폴드) 만 학습하면 됨 
	- 매니폴드 중 하나 안에서 두 입력 사이를 보간 하는것 가능 
- 일반화의 원천인 보간 
	- 지역 일반화(local generalization) : 이전에 본 것과 매우 유사한 것을 판단 
	- 보간 이외에 인지 매커니즘으로 궁극 일반화(extreme generalization) 도 사용 할 수 있음
```

#### 차이점
매니폴드는 고차원 데이터의 비선형적 구조를 이해하고, 그 데이터를 저차원으로 축소하는 데 사용됩니다. 복잡한 데이터 구조를 탐구하고 분석하는 데 유용. 

선형보간은 주어진 두 점 사이의 값을 단순하게 선형적으로 추정하는 방법. 주로 1차원적이고 직선적인 관계를 다루며, 계산이 매우 간단

![[Pasted image 20240928151214.png]]
- 희소 샘플링 : **희소 샘플링**은 잠재공간에서 **넓은 범위에 걸쳐 드문드문** 샘플을 선택하는 방법입니다. 이는 공간의 여러 부분에서 소수의 샘플을 선택하는 것을 의미
- 조밀한 샘플링 : **조밀한 샘플링**은 잠재공간에서 **특정 영역에 걸쳐 밀집**하여 샘플을 선택하는 방법입니다. 이는 잠재공간의 한정된 영역에서 많은 샘플을 선택하는 것을 의미

### 프루닝을 적용한 모델 압축 및 저장

`model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model) tf.keras.models.save_model(model_for_export, 'pruned_model.h5')`

- dropout의 경우 epoch마다 다른 모델을 통해 가중치를 업데이트 시켜나가므로 앙상블의 효과를 낼 수 있다.
- pruning의 경우 한번 잘라낸 **뉴런은 보관하지 않고** dropout의 경우 학습 시에 뉴런들을 랜**덤으로 껐다가 (보관해두고) 다시 켜는 과정**을 반복
- pruning : **파라미터 재사용 X** (why 재사용x? 모델 사용 메모리와 계산 자원 줄임!)
- dropout : **파라미터 재사용 O**, inference과정에서는 모든 파라미터 사용 (앙상블과 유사한 효과를 갖음)


## 작업 정의

### 입력 데이터는 무엇인지?
---
- 입력 데이터는 머신러닝 모델이 학습할 때 제공되는 정보
예) 영화 리뷰와 감성 테이블 태깅 → 영화 리뷰의 감성 분류 학습

### 당면한 문제가 어떤 종류인지?
---
• **이진 분류**: 스팸 감지, 신용카드 부정거래 감지와 같은 작업에서 두 가지 클래스 중 하나로 분류하는 작업.
• **다중 분류**: 여러 가지 클래스 중 하나로 분류하는 작업. 예를 들어, 영화 장르 분류.
• **스칼라 회귀**: 연속적인 숫자 값을 예측하는 작업.
• **벡터 회귀**: 다차원의 숫자 벡터를 예측하는 작업.

### 기존 솔루션은 어떤 것이 있는지?
---
- 기존의 솔루션은 이미 존재하는 해결 방법을 의미
예) 스팸 필터링/신용카드부정거래감지 → if문 구성 수동 알고리즘

### 고려해야 할 특별한 제약
---
시스템의 제약 사항 고려
예) 스팸 감지 시스템 : 엔드-투-엔드 방식(암호화) -> 처리 방식에 대한 제약


## 데이터 수집

### 대표성 없는 데이터 주의
---
- 훈련 데이터가 제품 환경의 데이터를 대표하지 못함(학습 품질과 실제 품질의 차이)
- 샘플링 편향 문제
    - 선거 당선 예측 → 실패
        - 이유: 전화설문결과 신뢰-투표 인구를 랜덤하게 대표한 샘플X. 즉 데이터 수집 과정에서부터 잘못되기에 예측대상과 상호 작용할 때 편향된 측정 결과를 나타냄
####  에너테이션 
- 데이터를 수동으로 레이블링하는 작업을 의미
	- 사람이 데이터를 보고 해당 데이터의 의미나 카테고리를 직접 지정하는 작업으로, 많은 시간과 노력이 필요한 노동집약적인 과정
	- 
- 타깃 누출(Target leaking)
	- 모델이 학습할 때 예측할 타깃 정보를 미리 알고 학습하게 되므로, 모델이 지나치게 높은 성능을

## 모델 개발

### 데이터 준비
---
벡터화:
- 신경망에서 모든 입력과 타깃은 일반적으로 부동 소수점 데이터로 이루어진 텐서

정규화:

- 비교적 큰 값이나 균일하지 않은 데이터를 신경망에 주입하면 업데이트할 그레디언트가 커져 수렴하는 것을 방해한다.
- 작은 값을 취해야 한다. (일반적으로 대부분의 값이 0~1 사이)
- 균일해야 한다. (모든 특성이 대체로 비슷한 범위)

### 평가 방법 선택
---
- 홀드아웃 검증 : 데이터가 풍부할 경우 사용
- K-겹 교차 검증 : 검증으로 사용할 샘플 개수가 너무 적을 경우 사용
- 반복 K-겹 교차 검증 : 데이터가 적고 정확한 모델 평가가 필요할 경우 사용

### 기준 모델 뛰어넘기
---
#### 통계적 검정력
- 아주 간단한 기준점을 넘을 수 있는 작은 모델 개발을 하기 위한 달성목표
- 특성 공학: 특성 선택 및 개발
- 구조에 대한 올바른 가정
- 좋은 훈련 옵션 선택 : 손실 함수, 배치 크기, 학습률 설정

### 모델 용량 키우기: 과대적합 모델 만들기
---
얼마나 큰 모델을 만들어야 하는지 알기 위해 과대적합된 모델을 만들어야한다. 검증 데이터에서 모델 성능이 감소하기 시작했을 때 과대적합에 도달한다.

1. 층을 추가
2. 층의 크기 키우기
3. epoch 수를 늘려서 훈련

### 모델 규제와 하이퍼파라미터 튜닝
---
반복적으로 모델을 수정하고 훈련하고 검증 데이터를 평가한다. 좋은 모델을 얻을 때까지 반복한다.

- 층을 추가하거나 제거
- dropout 추가
- 모델이 작다면 L1 이나 L2 규제 추가
- 하이퍼파라미터 바꿔서 시도

## 모델 배포

### 추론 모델 배치하기
### REST API로 모델 배포하기
---
- 서버나 클라우드 인스턴스에 텐서플로 설치 후 REST API로 모델의 예측 요청
- Flask를 사용해서 직접 serving 앱 생성 혹은 API 방식의 tensorflow serving 사용

### 장치로 모델 배포하기
---
#### 브라우저에 모델 배포하기
example. using rest API in product

머신러닝 예시는 아니지만, 대충 하단 제품들은 이렇게 생겼고 오른편 중앙 같은 인터페이스에 JS, java로 API활용해서 스크립트 짠다는 것 보여드리고 팠음

example. 모델이 배포되는 웹 브라우저
보통 제품들, 모니터링 모두 시각화 코드 짤 필요 없이 데이터만 연결하고 피쳐 같은거 정해주면(+a), 볼 수 있게 해놓아 볼 수 있게 해놓음

### 추론 모델 최적화
---
#### 가중치 가지치기(weight pruning):
- 가장 큰 가중치 값만 남겨 모델의 파라미터 개수를 낮춘다.
- 성능에는 약간의 손해를 보는 대신 모델의 메모리와 계산 자원을 줄인다.

- **가중치 양자화(weight quantization)**
	- 모델의 실행 성능과 효율성을 향상을 위해 신경망의 가중치(weight)와 활성화 함수(activation function) 출력을 더 작은 비트 수로 표현하도록 변환하는 기술
    - 가중치를 32bit에서 8bit로 압축하는 방법
    - 목표는 모델을 손상시키지 않으면서 모델의 크기를 줄이고 계산 비용을 낮추는 것
