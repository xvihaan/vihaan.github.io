---
layout: single
title:  "3.케창딥 - 머신러닝 워크플로"
categories: [AI, ML, DL]
tags: [keras, deeplearning, KDL]
toc: true
author_profile: false
---


# 신경망 기반 분류, 머신러닝 워크 플로우

## 매니폴드
---
복잡한 고차원 데이터가 실제로는 더 단순한 저차원 공간에 존재하는 구조
![[Pasted image 20240928140513.png]]

예시: 얼굴 이미지 데이터를 생각하면, 얼굴 이미지는 많은 픽셀(고차원)로 구성되어 있지만, 이 이미지들은 사실 눈의 위치, 코의 크기, 얼굴의 각도와 같은 몇 가지 저차원적인 요소들에 의해 설명될 수 있다.


## 이중분류, 다중분류 문제에서의 각각 손실함수 정의 및 설명
---
### **binary_crossentropy, categorical_crossentropy의 차이점**

1) 이진 분류에는 binary_crossentropy 를 사용 (멀티라벨)
- 이진 분류에서의 활성화 함수는 보통 sigmoid 를 사용하는데 0부터 1 사이의 값을 출력한다. 이로써 실제 클래스가 y=0, y=1이라면 예측 확률의 로그를 사용하여 손실을 계산

2) 다중 분류에서의 활성화 함수는 N개의 클래스에 대한 확률 분포를 출력하기 위해 softmax 를 사용.
- 범주형 인코딩하고 `categorical_crossentropy` 손실함수를 사용하는 방법으로 각 클래스에 대한 확률 분포를 다루는데 적합하며, 정수로 인코딩
- `sparse_categorical_crossentropy` 손실함수를 사용하는 방법으로는 one-hot 인코딩을 사용하지 않고도 동일한 결과를 얻을 수 있으며 메모리와 계산 효율성 측면에서 이점을 제공


 **회귀 손실함수 지표인 MAE와 RMSE 의 차이점, 이상치에 강건한 손실함수는?**

- RMSE와 MAE는 MSE 보다 이상치(outlier) 에 강건(robust)하다고 알려져 있다.
- MAE 와 RMSE 수식의 기반이 되는 $|x|$ , $\sqrt{x^2}$ 를 각각 그려보면 같은 모양이라는 것을 알 수 있다.

![[Pasted image 20240928142239.png]]

- **MAE**는 오차의 절대값 평균을 계산하므로, 모든 오차에 대해 동일한 가중치를 부여합니다. 따라서 이상치의 영향이 비교적 덜함
- **RMSE**는 오차의 제곱 평균의 제곱근을 계산하기 때문에, 큰 오차(이상치)에 매우 민감합니다. 이상치가 존재할 때 RMSE는 MAE보다 훨씬 더 크게 증가하는 경향

### **분류/회귀 문제에 따른 사용가능한 compile 3가지 단계별 항목**

### Optimizer
---

| 이름      | 특징                                                                                                                                                               | name       |
| ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- |
| SDG     | - 경사하강법 알고리즘.  <br>- 각 배치마다 가중치를 업데이트  <br>- 모멘(Momentum)을 추가여면 경사하강 방향을 조절하고 빠르게 수렴 가능함.                                                                        | .SGD()     |
| RMSprop | SGD의 단점 해결(학습률 설정), 기울기 제곱의 이동평균값을 구하여 학습률 조절 - 범                                                                                                                | .RMSprop() |
| Adam    | **- 모멘텀**(Momentum)과 **RMSprop**을 결합한 알고리즘  <br>- 학습 속도와 안정성을 모두 맞춘 알고리즘으로 알려졌고,  <br>- 1, 2차 모멘트를 이용해 학습률을 적응적으로 조정함  <br>- 다른 옵티마이져 보다 더 안정적이어서 복잡한 모델에 자주 사용됨 | .Adam()    |
| Adagard | - 자주 업데이트되는 매개변수에는 작은 학습률을, 덜 업데이트되는 매개변수에는 큰 학습률을 적용  <br>- 각 매개변수마다 학습률을 다르게 적용하여 드물게 발생하는 특징의 가중치 업데이트 촉진 (?)  <br>-매우 긴 학습이 필요한 경우에 효율적                      | .Adagrad() |

### Loss
---

| 이름                            | 특징                                                                | name                                                |
| ----------------------------- | ----------------------------------------------------------------- | --------------------------------------------------- |
| mean_squared_error            | (회귀 문제)<br><br>추론값과 target값의 차이의 제곱의 평균                           | `tf.keras.losses.MSE()`                             |
| CategoricalCrossentropy       | (다중분류 문제)<br>  <br>softmax 결과값과  <br>target - onehot encoding과 대응 | `tf.keras.losses.categorical_crossentropy()`        |
| SparseCategoricalCrossentropy | (다중 분류 문제)<br><br>정답 레이블을 원핫인코딩하지 않고, 정수값으로 사용하는 경우               | `tf.keras.losses.Sparse_categorical_crossentropy()` |
| KLDivergence                  | 생성모델과 분류모델에서 사용됨  <br>두 확률 분포간의 차이를 측정하는 지표                       | `tf.keras.losses.KLDivergence`                      |

### Metric
---

| 이름                                | 특징                                                              | name 또는 예                             |
| --------------------------------- | --------------------------------------------------------------- | ------------------------------------- |
| accuracy                          | 모델의 예측값과 실제값이 일치하는 비율 계산                                        | `“accuracy”`                          |
| cosine_similarity                 | 유사성 비교에서 사용되는 평가 지표. 두 벡터 간의 코사인 유사도를 계산  <br>(텍스트 문제사용)        | `"cosine_similarity"`                 |
| sparse top k categorical accuracy | 정수 형태의 레이블을 사용하는 다중 분류 문제, 상위 K개의 클래스 중에 실제 클래스가 포함되어 있는 경우를 계산 | `“sparse_top_k_categorical_accuracy”` |
| mean squared error                | 회귀 문제, 예측값과 실제값의 제곱 오차를 계산                                      | `“mean_squared_error”`                |

### Overfitting을 해결하기 위한 방법
1) 더 많은 데이터 수집
- Overfitting은 주로 학습 데이터가 적을 때 발생. 따라서 더 많은 데이터를 수집하여 학습 데이터의 양을 늘리는 것이 해결책 중 하나이다.

2) 모델의 복잡도 감소
- 모델의 복잡도를 줄이는 것도 Overfitting을 해결하는 데 도움이 된다. 예를 들어, 의사결정나무(Decision Tree)의 최대 깊이를 제한하거나 신경망(Neural Network)의 은닉층 수를 줄이는 등의 방법을 사용할 수 있다.

3) Regularization 사용
- Regularization은 모델의 복잡도를 줄이면서 Overfitting을 방지하는 기술. L1, L2 등의 규제 항을 추가하여 모델의 가중치(wieght)를 제한하는 방식으로 동작

4) Dropout 사용
- Dropout은 신경망에서 많이 사용되는 방법으로, 학습 과정에서 일부 뉴런을 임의로 제거하여 모델의 복잡도를 줄임. 이를 통해 Overfitting을 방지하고, 모델의 일반화 성능을 향상시킬 수 있다.

5) Early Stopping 기법
- Early Stopping은 학습 과정 중에 검증 데이터(validation data)의 오차가 증가하기 시작할 때 학습을 멈추는 방식. 이를 통해 학습 데이터에 Overfitting되는 것을 방지

6) Cross Validation 기법
- Cross Validation은 모델의 일반화 성능을 평가하기 위한 기술로, 데이터를 여러 개의 Fold로 나누어 각 Fold를 순서대로 검증 데이터로 사용하는 방식. 이를 통해 모델의 일반화 성능을 더 정확하게 평가할 수 있으며, Overfitting을 방지하는 데에도 도움이 된다.


## 기계 학습 프로세스
---
### 1. 문제 정의 (Problem Definition)
- **설명**: 해결하려는 문제를 명확하게 정의하는 단계입니다. 예를 들어, 고객이 제품을 구매할지 여부를 예측하는 문제(분류)나 집값을 예측하는 문제(회귀)일 수 있습니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 예측하고자 하는 목표가 이산적(예: 구매 여부, 질병 여부 등).
    - **회귀**: 예측하고자 하는 목표가 연속적(예: 집값, 온도 등).

### 2. 데이터 확보 (Data Collection)
- **설명**: 모델을 훈련하기 위해 필요한 데이터를 수집하는 단계입니다. 이 데이터는 문제를 해결하는 데 필요한 특징(특성)을 포함하고 있어야 합니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 데이터셋에 타겟 레이블이 이산적(예: 0 또는 1).
    - **회귀**: 데이터셋에 타겟 레이블이 연속적(예: 실제 값).

### 3. 데이터 전처리 (Data Preprocessing)
- **설명**: 데이터의 품질을 높이기 위해 결측치 처리, 이상치 제거, 스케일링, 정규화 등을 수행하는 단계입니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 레이블 인코딩(예: 원-핫 인코딩), 클래스 불균형 처리(SMOTE 등).
    - **회귀**: 목표 변수의 스케일링(예: 로그 변환), 이상치 처리.

### 4. 데이터 특징 추출 (Feature Extraction)
- **설명**: 모델에 중요한 영향을 미칠 수 있는 특징을 생성하거나 선택하는 단계입니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 특정 클래스와 관련된 특징 선택, 텍스트나 이미지 데이터에서 특징 추출.
    - **회귀**: 연속적인 변수 사이의 관계를 반영한 특징 생성(예: 다항식 특징).

### 5. 모델 준비 (Model Preparation)
- **설명**: 문제를 해결할 수 있는 기계 학습 모델을 선택하고, 초기 설정을 구성하는 단계입니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 로지스틱 회귀, 랜덤 포레스트, SVM 등 분류 모델 선택.
    - **회귀**: 선형 회귀, 라쏘 회귀, XGBoost 등 회귀 모델 선택.

### 6. 모델 학습 (Model Training)
- **설명**: 준비된 모델을 사용하여 학습 데이터를 기반으로 가중치를 학습하는 단계입니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 이진 또는 다중 클래스 분류 문제에 맞게 학습.
    - **회귀**: 목표 변수가 연속적인 회귀 문제에 맞게 학습.

### 7. 모델 튜닝 (Model Tuning)
- **설명**: 모델의 성능을 최적화하기 위해 하이퍼파라미터를 조정하는 단계입니다. 교차 검증과 같은 기법을 사용합니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 분류기 특성에 맞는 하이퍼파라미터 튜닝(예: C, max_depth).
    - **회귀**: 회귀 모델 특성에 맞는 하이퍼파라미터 튜닝(예: alpha, learning rate).

### 8. 모델 평가 (Model Evaluation)
- **설명**: 테스트 데이터를 사용하여 모델의 성능을 평가하는 단계입니다. 적절한 평가 지표를 선택하여 모델의 정확도를 판단합니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 정확도, 정밀도, 재현율, F1-score, ROC-AUC 등의 지표 사용.
    - **회귀**: MSE, RMSE, MAE, R^2 등의 지표 사용.

### 9. 모델 비교 (Model Comparison)
- **설명**: 여러 모델의 성능을 비교하여 최종적으로 사용할 모델을 선택하는 단계입니다.
- **분류/회귀에 따른 차이**:
    - **분류**: 분류 모델들 간의 성능 비교.
    - **회귀**: 회귀 모델들 간의 성능 비교.

### 10. 모델 서빙 (Model Deployment)
- **설명**: 최종 선택된 모델을 실제 환경에 배포하여 실시간 예측을 수행하는 단계입니다.
- **분류/회귀에 따른 차이**:
    - **분류/회귀**: 모델 유형에 따라 서빙 방법은 유사할 수 있으며, 웹 서비스, API, 임베디드 시스템 등에 모델을 배포합니다.

