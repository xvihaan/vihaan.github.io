---
layout: single
title:  "4.빅데이터 머신러닝 기반 데이터분석"
categories: [bigdata, AI]
tags: [Major, BigData]
toc: true
author_profile: false
---


# 1. 머신러닝

머신러닝(Machine Learning)은 빅데이터와 사물인터넷(IoT) 시대에서 유용한 정보를 생성해주는 중요한 역할을 제공한다.
머신러닝은 알고리즘을 통해서 데이터를 예측하는 인공지능의 일종으로 사람의 개입이 최소화된 환경에서 데이터에 의한 학습을 통해 최적의 판단이나 예측을 가능하게 해주는 것으로 크게 지도학습과 비지도학습(자율학습)으로 분류된다.

![bd_4_1]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_1.png)


## 머신 러닝
- **지도 학습**(Supervised Learning): 문제와 정답을 모두 알려주고 공부시키는 방법
- **비지도 학습**(Unsupervised Learning): 답을 가르쳐주지 않고 공부시키는 방법
- **강화 학습**(Reinforcement Learning): 보상을 통해 상은 최대화, 벌은 최소화하는 방향으로 행위를 강화하는 학습

- **기계학습**은 크게 **지도학습**과 **비지도학습**으로 분류된다.
- 지도학습은 사전에 입력과 출력에 대한 정보를 가지고 있는 상태에서 입력이 들어오는 경우 해당 출력이 나타나는 **규칙을 발견**(알고리즘 이용)하고, 이를 통해서 만들어진 모델(model)에 의해서 **새로운 데이터를 추정 및 예측**한다.
- 비지도학습은 최종적인 정보가 없는 상태에서 컴퓨터 스스로 공통점과 차이점 등의 **패턴을 이용해서 규칙을 생성**하고, 이를 통해서 분석결과를 도출해내는 방식이다. 따라서 유사한 데이터를 그룹화해주는 **군집화**와 군집 내의 특성을 나타내는 **연관분석 방법**에 주로 이용된다. 아래 표는 지도학습과 비지도학습의 차이점을 나타내고 있다.

| 분류  | 지도학습                | 비지도학습               |
| :-- | ------------------- | ------------------- |
| **주관**  | 사람의 개입에 의한 학습       | 컴퓨터에 의한 기계학습        |
| **기법**  | 확률과 통계기반 추론통계       | 패턴분석 기반 데이터 마이닝     |
| **유형**  | 회귀분석, 분류분석(y 변수 있음) | 군집분석, 연관분석(y 변수 없음) |
| **분야**  | 인문, 사회 계열           | 공학, 자연 계열           |


## 모델링과 예측

### 모델링이란?
우리가 살고 있는 현실 세계에서 일어나는 현상을 수학적으로 표현하는 행위
- 모델링을 통해 모델을 알아내고 나면, 모델을 이용하여 새로운 사실을 예측할 수 있게 된다.

### 모델링과 예측 예시

```
조건: 100만원 기본급에 자동차 1대를 팔 때마다 90만원을 추가로 받는다.
모델: y = 900000x + 1000000    # -> 의사코드 -> 코딩
```

- 주어진 조건으로부터 변수를 뽑고 변수 사이의 관계를 나타내는 식을 구하는 과정을 모델링(modeling)으로 볼 수 있음
- 모델을 가지고 있으면 예측(prediction)이 가능함

데이터 과학의 세계에서는 문장으로 기술된 조건이 주어지는 대신, 데이터가 주어짐. 데이터로 부터 모델을 알아내야 하는데, 주어진 데이터를 `훈련집합(training set)`이라 부르며, 앞으로 훈련 집합을 식(1) 과 같이 표현

![bd_4_2]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_2.png)

식(1) `X={x1​,x2​,…,xn​}, Y={y1​,y2​,…,yn​}`

- 데이터 과학에서는 독립 변수 x를 설명변수, 종속 변수 y를 반응 변수라고 부른다.

---


# 2. 모형평가

## 모형평가 기준

분류분석 모형의 평가는 예측 및 분류를 위해 구축된 모형이 임의의 모형보다 더 우수한 분류 성과를 보이는지와 고려된 서로 다른 모형들 중 어느 것이 가장 우수한 예측 및 분류 성과를 보유하고 있는지 등을 비교 분석하는 과정

분석 모형에는 다양한 알고리즘 및 방법론이 존재할 뿐만 아니라 하나의 방법론에도 다른 분류 결과를 초래하는 선택사항이 존재


## 교차검증

모델을 만드는 것은 가지고 있는 샘플 데이터를 이용하여 충분한 정확도로 일반화시켜야 한다.

이를 위해 샘플 데이터를 training / validation / test dataset 으로 나누어 모형의 성과를 검증
이는 주어진 데이터에서만 높은 성과를 보이는 모형의 과적합(Overfitting) 문제를 해결하기 위한 단계로 잘못된 가설을 가정하게 되는 2종 오류의 발생을 방지할 수 있다.

이 단계를 위하여 사용되는 추출법에는 대표적으로 홀드아웃(Hold-out), k-fold 교차 검증, 붓스트랩(Bootstrap) 방법 등이 있다.

### 교차검증의 데이터 구분

| 데이터 구분                       | 설명                                |
| :--------------------------- | :-------------------------------- |
| **학습데이터(training data)**         | 훈련용 데이터라고 한다                      |
| **학습데이터(training data)**         | 분류기를 만들 때 사용하는 데이터                |
| **학습데이터(training data)**         | 데이터 마이닝의 모델을 학습할 때 사용             |
| **검증(검정) 데이터 (validation data)** | 구축된 모형의 과대추정 또는 과소추정을 미세조정 하는데 활용 |
| **검증(검정) 데이터 (validation data)** | 분류기의 파라미터 값을 최적화하기 위해 사용하는 데이터    |
| **평가(시험) 데이터 (test data)**       | 모형의 구축과는 상관없는 외부데이터를 의미           |
| **평가(시험) 데이터 (test data)**       | 모델의 성능을 검증하기 위한 데이터               |


## 홀드 아웃 (Hold-out)
- 주어진 원천 데이터를 랜덤하게 두 분류로 분리하여 교차검정을 실시하는 방법으로 하나는 모형의 학습 및 구축을 위한 훈련용 자료로 하나는 성과평가를 위한 검증용 자료로 사용
- 홀드아웃 방법에서는 일반적으로 전체 데이터 중 70%의 데이터는 훈련용 자료로 사용하고 나머지는 검증용 자료로 사용
- 검증용 자료의 결과는 분류분석 모형에는 영향을 미치지 않고 성과 측정만을 위하여 사용

![bd_4_3]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_3.png)


## K-fold 교차검증 (k-fold Cross Validation)
- 교차 검증은 주어진 데이터를 가지고 반복적으로 성과를 측정하여 그 결과를 평균한 것으로 분류분석 모형을 평가하는 방법
- 대표적인 k-fold 교차검증은 전체데이터를 사이즈가 동일한 k개의 하부집합으로 나누고 k번째의 하부 집합을 검증용 자료로, 나머지 k-1개의 하부집합을 훈련용 자료로 사용, 이를 k번 반복, 측정하고 각각의 반복측정 결과의 평균값을 최종 평가로 사용
- 일반적으로 10-fold 교차검증이 사용

![bd_4_4]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_4.png)


## 붓스트랩(Bootstrap)
- 붓스트랩은 주어진 자료에서 **단순 랜덤 복원추출 방법**을 활용하여 동일한 표본의 크기의 표본을 여러 개 생성하는 복원추출법
- 붓스트랩은 평가를 반복한다는 측면에서 **k-fold 교차검증**과 유사하나 **훈련용 자료를 반복 재산정**한다는 점에서 차이가 있다
- 붓스트랩은 전체 데이터의 양이 크지 않은 경우의 **모형 평가에 가장 적합**하다
- 전체 데이터 sample 이 N개이고 붓스트랩으로 N개의 sample 을 추출하는 경우 특징 샘플이 학습 데이터에 포함될 확률은 약 63.2% 이다.
- 반대로 sample에 한 번도 선택되지 않는 확률은 약 36.8%가 해당
- 한 번도 포함되지 않는 sample은 평가용 데이터로 사용


## 분류모형 평가 지표
### 오분류표, 혼동행렬 (Confusion Matrix)

일반적으로 혼동행렬(Confusion Matrix)는 머신러닝에 의해서 생성된 분류분석 모델의 성능을 지표화 할 수 있는 테이블로 모델에 의해서 예측한 값은 열(column)으로 나타나고, 관측치의 값은 행(row)로 표시

**혼돈 매트릭스**에서 
- 참 긍정(TP)은 관측치가 YES -> 모델 YES
- 거짓 부정(FN)은 관측지가 YES -> 모델 NO
- 거짓 긍정(FP)은 관측지가 NO -> 모델 YES
- 참 부정(TN)은 관측지가 NO -> 모델 NO

![bd_4_5]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_5.png)

![bd_4_6]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_6.png)

![bd_4_7]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_7.png)



---


# 3. 의사결정나무(Decision Tree)

## 의사결정나무의 개념

의사결정 규칙을 나무구조로 나타내어 전체 자료를 몇 개의 소집단으로 분류하거나 예측을 수행하는 분석방법


![bd_4_8]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_8.png)


## 의사결정나무의 분리 기준

의사결정나무는 여러 분기로 이루어진 구조. 따라서 정확한 예측을 위해서는 분류 기준이 핵심적 요소

![bd_4_9]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_9.png)

순수도라는 것은 목표변수의 특정 범주에 개체들이 포함되어 있는 정도
결국 분리기준이란 것은 부모마디에 비해 자식마디에서 순수도가 증가하는 정도를 수치화한 것


### 의사결정나무 모형의 분류

#### 분류나무(Classification tree)

![bd_4_10]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_10.png)

#### 회귀나무(Regression tree)

![bd_4_11]({{site.url}}/assets/images/2024-3-1-bigdata/bd_4_11.png)

## 의사결정나무의 장/단점

| 장점                                            | 단점                               |
| :-------------------------------------------- | -------------------------------- |
| 구조가 단순하여 해석이 용이                               | 분류 기준값의 경계선 부근의 자료값에 대해서는 오차가 큼  |
| 유용한 입력변수의 파악과 예측변수 간의 상호작용 및 비선형성을 고려하여 분석 가능 | 로지스틱 회귀와 같이 각 예측변수의 효과를 파악하기 어렵다 |
| 선형성, 정규성, 등분산성 등의 수학적 가정이 불필요한 비모수적 모형        | 새로운 자료에 대한 예측이 불안정할 수 있다         |
| 계산 비용이 낮아 대규모의 데이터셋에서도 비교적 빠르게 연산 가능          |                                  |
| 수치형/범주형 변수를 모두 사용                             |                                  |



